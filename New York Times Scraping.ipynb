{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1moa5Tv7L0zb4hP2vHFlSTTgfmHkJ491H","timestamp":1664985389008},{"file_id":"https://github.com/jeremyallenjacobson/qtm350/blob/master/CourseAssets/TimesAPI_Sp20_350.ipynb","timestamp":1663166321003}],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0L0fH5B88hvp"},"source":["# New York Times Scraping\n","[The New York Times Developer Network](https://developer.nytimes.com/)"]},{"cell_type":"code","metadata":{"id":"Rp8gbY1W8ZFU"},"source":["import getpass\n","APIKEY = getpass.getpass()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3kIeZe5_bBHr"},"source":["## Making API calls using terminal/Linux\n"]},{"cell_type":"markdown","source":["Use curl to request information from the url and use the -o tag to save that info to a new file, trial.json."],"metadata":{"id":"DuK--ZoZJacz"}},{"cell_type":"code","source":["!curl --request GET -o trial.json \"https://api.nytimes.com/svc/archive/v1/1970/12.json?api-key=3dUdJXnmS3zDOlHayoM04BUes1cgevHp\""],"metadata":{"id":"3-c2a5gGmsfc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UoeFEKDy0guv"},"source":["### Viewing the JSON\n"]},{"cell_type":"markdown","source":["We can use jq in terminal to view and filter jsons. Install jq using sudo and view the json by passing trail.json to jq."],"metadata":{"id":"FKVgNEpSKMdM"}},{"cell_type":"code","source":["!sudo apt-get install jq\n","!jq < trial.json"],"metadata":{"id":"pxhjf4LS5SJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head trial.json"],"metadata":{"id":"7rCN8QWp5ziG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gc8ntgU16Xqe"},"source":["### Filtering using `jq`\n","To filter based on key, use `jq '.key'`, where `.key` is one of the keys from the json file, and `jq` will return the corresponding values in the json."]},{"cell_type":"code","source":["from __future__ import print_function"],"metadata":{"id":"fa3h69KAKVGY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To grab just the articles, we want to filter through the `.docs` tag and save the output to trialarticles.json."],"metadata":{"id":"2KSAT8i1LVkr"}},{"cell_type":"code","source":["!jq < trial.json\n","!jq '.response | .docs ' < trial.json > trialarticles.json"],"metadata":{"id":"GgII7OY5hahM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also grab one random article (in this case, the fourth) by pulling the fourth element from the array of articles. We can then filter further using the `.headline` and `.main` tags."],"metadata":{"id":"-z8393FXLohR"}},{"cell_type":"code","source":["!jq '.response | .docs '[3] < trial.json > trialex.json\n","!jq '.headline | .main' < trialex.json"],"metadata":{"id":"-x8d7IMlLRfU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## API requests using Python"],"metadata":{"id":"EOGjbgO4L4dG"}},{"cell_type":"markdown","source":["We also stick with Python for the entire process. First, we import the requests package."],"metadata":{"id":"lXzZYCvkMJcQ"}},{"cell_type":"code","source":["import requests as req"],"metadata":{"id":"dE4Fjr8IP3Nm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using the same url, we can pull the json file and save it to a local variable."],"metadata":{"id":"n7mOYL57MNuR"}},{"cell_type":"code","source":["url = \"https://api.nytimes.com/svc/archive/v1/1970/12.json?api-key=3dUdJXnmS3zDOlHayoM04BUes1cgevHp\"\n","response = req.get(url).json()\n","response"],"metadata":{"id":"FJITmbvzPkOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qD5Z4iur-V56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can then save the array of articles in a local array called \"articles.\" After filtering through the json to get just the information under `.docs`, we loop through every element in that array and pull the main headline, abstract and lead paragraph. We then append all that information to \"articles\" and view the first five items."],"metadata":{"id":"BwhvK6JZMind"}},{"cell_type":"code","metadata":{"id":"l845wOng7wdy"},"source":["articles = []\n","docs = response['response']['docs']\n","for doc in docs:\n","  filteredDoc = {}\n","  filteredDoc['title'] = doc['headline']['main']\n","  filteredDoc['abstract'] = doc['abstract']\n","  filteredDoc['paragraph'] = doc['lead_paragraph']\n","  articles.append(filteredDoc)\n","articles[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQxO2rg2BBEY"},"source":["# From JSON to csv\n","For working with structured data in notebooks, the most popular and full-featured packages is `pandas`, which can tranform the json into a csv file.\n","\n","First we import the pandas package. It is a common convention to import it under the *alias* `pd` so that you do not need to type pandas over and over again when referring back to the package name."]},{"cell_type":"code","metadata":{"id":"ryWTAEdQBuV0"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrKCU57MCDCH"},"source":["Then, we use the `read_json()` function in pandas to transform the filtered json into a dataframe."]},{"cell_type":"code","metadata":{"id":"qLOhVPw2CSXk"},"source":["dfterm = pd.read_json('trialarticles.json')\n","dfterm.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfterm.to_csv('trialarticles.csv')"],"metadata":{"id":"QS0tQaa2P-9V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is how we would perform the same transformation in python: \"articles\" is a list, so it requires a different pandas function."],"metadata":{"id":"yAkHQloDPh--"}},{"cell_type":"code","source":["pythondf = pd.DataFrame(articles)\n","pythondf.head(5)"],"metadata":{"id":"KyxpHICuPTE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pythondf.to_csv('pythontrialarticles.csv')"],"metadata":{"id":"iN-qtsVaQA07"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trying to obtain full body text"],"metadata":{"id":"F9922j_BPrtd"}},{"cell_type":"markdown","source":["The urls within the terminal dataframe links to an html file, which is pretty messy and does not include the body of an article."],"metadata":{"id":"Q5zFX2yRH1mn"}},{"cell_type":"code","metadata":{"id":"NI_y-BpODLfV"},"source":["dfterm['web_url'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HyGgH8bEW7V"},"source":["Here is where we can see the error message: \"Please enable JS and disable any ad blocker.\" Selenium required for further operations, but even then it's unclear whether or not the body will be available."]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import requests as req\n","Web = req.get(\"https://www.nytimes.com/1970/12/01/archives/egebergs-ouster-is-expected-soon-dismissal-of-health-official-seen.html\")\n","S = BeautifulSoup(Web.text, 'lxml')\n","print(S.prettify())"],"metadata":{"id":"3TvHTSnvt8Jf"},"execution_count":null,"outputs":[]}]}