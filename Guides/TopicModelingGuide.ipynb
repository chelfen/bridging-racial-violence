{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Guide\n",
    "\n",
    "This notebook is a guide to creating topic models for the words contained in the articles. This notebook using the [LDA](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2) topic modeling technique to create interactive HTML topic model visualizations. To ensure accuracy, please check the quality of the data before proceeding â€” ideally, the text should be pre-processed. A code cell containing the pre-processing algorithm is included in the NGramsGuide.ipynb file if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the necessary packages. It may be necessary to ![install](https://packaging.python.org/en/latest/tutorials/installing-packages/) the packages if they are not already in your Python kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data set(s). Change the argument to include the path on your local computer that leads to the file. For example, if the file is in your Downloads folder, the path may look like /Users/firstnamelastname/Downloads/Bridging Racial Violence Compiled Data.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl41 = pd.read_csv('/Users/clairefenton/Desktop/Emory/BRV Research/Data/ATL_1941_new_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word List Creation\n",
    "\n",
    "Create a word list for the topic models using the following parameters:\n",
    "* df: the data set\n",
    "* text_col: a string value representing the name of the column in df containing the pre-processed text\n",
    "* words_to_remove: a list of strings containing words to be removed from the word list\n",
    "\n",
    "Th `words_to_remove` parameter should be used to remove any common words from the word list that do not provide value to the topic models (i.e. \"say,\" \"was,\" \"they\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_list(df, text_col, words_to_remove):\n",
    "    word_list = [x.split() for x in df[text_col]]\n",
    "\n",
    "    cleaned_word_list = []\n",
    "    for word in words_to_remove:\n",
    "        for list in word_list:\n",
    "            cleaned_word_list.append([x for x in list if x != word])\n",
    "    return cleaned_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Creation\n",
    "\n",
    "Create a topic model using the following parameters:\n",
    "* word_list: the word list created from the `create_word_list` function\n",
    "* n: an integer value representing the number of topics to be included in the model\n",
    "* year: a string value representing the year(s) from which the data comes\n",
    "* file_path: a string value representing the file path to which the HTML topic models should be saved \n",
    "\n",
    "The cell block contains an optional argument `plt.ylim(min, max)` that can adjust the range of the y-axis. Use as necessary to make the graph more visually appealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topic_model(word_list, n, year, file_path):\n",
    "    id2word = corpora.Dictionary(word_list)\n",
    "    texts = word_list\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    num_topics = n\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=num_topics)\n",
    "    doc_lda = lda_model[corpus]\n",
    "    pyLDAvis.enable_notebook()\n",
    "    LDAvis_data_filepath = os.path.join(file_path+str(num_topics))\n",
    "    if 1 == 1:\n",
    "        LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "        with open(LDAvis_data_filepath, 'wb') as f:\n",
    "            pickle.dump(LDAvis_prepared, f)\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "    pyLDAvis.save_html(LDAvis_prepared, file_path + 'BRV_' + year + '_' + str(num_topics) +'.html')\n",
    "    LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, filter the data set for articles only containing instances of racial violence before creating the word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl41_rv = atl41[atl41['entry'] == 1]\n",
    "word_list_41 = create_word_list(atl41_rv, 'text_x', ['say', 'there'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example creation of a topic model containing 27 topics from the Atlanta Daily World 1941 articles containing instances of racial violence. The file is saved to `/Users/clairefenton/Downloads/` with the name `BRV_1941_27.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_topic_model(word_list_41, 27, '1941', '/Users/clairefenton/Downloads/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create multiple topic models from the same data, sometimes a loop can be helpful. The below loop creates topic models in five-topic increments, starting at 25 topics and ending at 45 topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25, 50, 5):\n",
    "    create_topic_model(word_list_41, i, '1941', '/Users/clairefenton/Downloads/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
